# main.py
from __future__ import annotations

import os
import time
import html
import random
from datetime import datetime, timedelta, timezone
from typing import List, Dict, Any

import httpx
from bs4 import BeautifulSoup
from fastapi import FastAPI, Request, Query
from fastapi.responses import HTMLResponse, JSONResponse, PlainTextResponse
from fastapi.staticfiles import StaticFiles

# === —á—Ç–æ–±—ã TMDB_API_KEY –ø–æ–¥—Ç—è–Ω—É–ª—Å—è –∏–∑ .env ===
try:
    from dotenv import load_dotenv  # type: ignore
    load_dotenv()
except Exception:
    pass

APP_TITLE = "–ú–æ—è –ø–æ–¥–±–æ—Ä–∫–∞"
MSK_TZ = timezone(timedelta(hours=3))
# –í–†–ï–ú–Ø –ñ–ò–ó–ù–ò –ö–≠–®–ê –î–õ–Ø –ö–ê–ñ–î–û–ô –¢–ï–ú–´
DEFAULT_TTL = 15 * 60  # 15 –º–∏–Ω—É—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

TOPIC_TTL = {
    "afisha": 2 * 60 * 60,   # 2 —á–∞—Å–∞
    "series": 24 * 60 * 60,  # 24 —á–∞—Å–∞
    "movies": 24 * 60 * 60,  # 24 —á–∞—Å–∞
    "agro":   2 * 60 * 60,   # 2 —á–∞—Å–∞
    "svo":    10 * 60,       # 10 –º–∏–Ω—É—Ç
    "ai":     60 * 60,       # 1 —á–∞—Å
}

def get_ttl(topic: str) -> int:
    return TOPIC_TTL.get(topic, DEFAULT_TTL)

HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/126.0 Safari/537.36"
    ),
    "Accept-Language": "ru-RU,ru;q=0.9,en;q=0.8",
}

TMDB_API_KEY = os.getenv("TMDB_API_KEY", "").strip()  # TMDB v3 API key

# –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–∞—Ä—Ç–∏–Ω–∫–∏ —Ç–µ–º (–æ–¥–Ω–∞ –Ω–∞ —Ç–µ–º—É)
TOPIC_IMAGES = {
    "afisha": "https://images.unsplash.com/photo-1514525253161-7a46d19cd819?q=80&w=1200&auto=format&fit=crop",
    "series": "https://images.unsplash.com/photo-1585951237318-9ea5e175b891?q=80&w=1200&auto=format&fit=crop",
    "movies": "https://images.unsplash.com/photo-1489599849927-2ee91cede3ba?q=80&w=1200&auto=format&fit=crop",
    "agro": "https://images.unsplash.com/photo-1464226184884-fa280b87c399?q=80&w=1200&auto=format&fit=crop",
    "svo": "https://images.unsplash.com/photo-1500530855697-b586d89ba3ee?q=80&w=1200&auto=format&fit=crop",  # –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π –ø–µ–π–∑–∞–∂
    "ai": "https://images.unsplash.com/photo-1518770660439-4636190af475?q=80&w=1200&auto=format&fit=crop",
}

# Telegram-–∫–∞–Ω–∞–ª—ã (–±–µ–∑ @ / t.me/)
SVO_TELEGRAM = ["bloodysx", "bbbreaking", "Alexey_Pivo_varov", "mash"]
AFISHA_TELEGRAM = ["sysoevfm", "instafoodpassion"]
AGRO_TELEGRAM = ["svoe_fermerstvo", "agro_nomika", "agroinvestor", "mcxae", "mcx_ru"]

# –ö—ç—à –≤ –ø–∞–º—è—Ç–∏
CACHE: Dict[str, Dict[str, Any]] = {}

app = FastAPI(title=APP_TITLE)

app.mount("/static", StaticFiles(directory="static"), name="static")
# –£–±–∏—Ä–∞–µ–º –±—Ä–∞—É–∑–µ—Ä–Ω–æ–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ ngrok
@app.middleware("http")
async def add_skip_warning_header(request: Request, call_next):
    resp = await call_next(request)
    resp.headers["ngrok-skip-browser-warning"] = "true"
    return resp

# –ü—Ä–æ—Å—Ç–æ–π healthcheck (–¥–ª—è curl)
@app.get("/health", response_class=PlainTextResponse)
async def health() -> PlainTextResponse:
    return PlainTextResponse("ok")

def now_ts() -> int:
    return int(time.time())


def cache_get(topic: str) -> List[Dict[str, Any]] | None:
    rec = CACHE.get(topic)
    if not rec:
        return None
    ttl = rec.get("ttl") or get_ttl(topic)
    ts = rec.get("ts", 0)
    if now_ts() - ts > ttl:
        return None
    return rec.get("items") or None


def cache_set(topic: str, items: List[Dict[str, Any]]):
    CACHE[topic] = {
        "ts": now_ts(),
        "ttl": get_ttl(topic),
        "items": items,
    }

def short(txt: str, limit: int = 240) -> str:
    t = " ".join((txt or "").split())
    return t if len(t) <= limit else t[: limit - 1].rstrip() + "‚Ä¶"

async def fetch_json(client: httpx.AsyncClient, url: str, **params) -> Dict[str, Any] | None:
    try:
        r = await client.get(url, params=params, headers=HEADERS, timeout=20)
        if r.status_code == 200:
            return r.json()
    except Exception:
        pass
    return None

async def fetch_html(client: httpx.AsyncClient, url: str) -> str | None:
    try:
        r = await client.get(url, headers=HEADERS, timeout=20)
        if r.status_code == 200:
            return r.text
    except Exception:
        pass
    return None

def parse_tg_list(html_text: str, base_url: str) -> List[Dict[str, Any]]:
    out: List[Dict[str, Any]] = []
    if not html_text:
        return out
    soup = BeautifulSoup(html_text, "html.parser")
    wraps = soup.select(".tgme_widget_message_wrap")
    for w in wraps:
        txt_tag = w.select_one(".tgme_widget_message_text")
        text = txt_tag.get_text(" ", strip=True) if txt_tag else ""
        if not text:
            continue
        ts = 0
        t_tag = w.select_one("time")
        if t_tag and t_tag.has_attr("datetime"):
            try:
                dt = datetime.fromisoformat(t_tag["datetime"].replace("Z", "+00:00"))
                ts = int(dt.timestamp())
            except Exception:
                ts = 0
        link = base_url
        a_tag = txt_tag.select_one("a[href]") if txt_tag else None
        if a_tag and a_tag["href"].startswith(("http://", "https://")):
            link = a_tag["href"]
        img = ""
        p = w.select_one("a.tgme_widget_message_photo_wrap, a.tgme_widget_message_video_thumb")
        if p and p.has_attr("style"):
            st = p["style"]
            if "url(" in st:
                start = st.find("url(") + 4
                end = st.find(")", start)
                candidate = st[start:end].strip("'\"")
                if candidate.startswith("http"):
                    img = candidate
        out.append({
            "title": short(text, 120),
            "summary": short(text, 320),
            "url": link,
            "image": img,
            "ts": ts
        })
    return out

async def get_telegram_news(channels: List[str], limit_per_channel: int = 4, total_limit: int = 10) -> List[Dict[str, Any]]:
    items: List[Dict[str, Any]] = []
    async with httpx.AsyncClient(follow_redirects=True) as client:
        for ch in channels:
            page = await fetch_html(client, f"https://t.me/s/{ch}")
            parsed = parse_tg_list(page or "", f"https://t.me/{ch}")
            if parsed:
                items.extend(parsed[:limit_per_channel])
    items.sort(key=lambda x: x.get("ts", 0), reverse=True)
    for it in items:
        it.pop("ts", None)
    return items[:total_limit]


def _daily_seed(salt: str = "") -> str:
    # –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–æ–ª—å –Ω–∞ —Ç–µ–∫—É—â–∏–π –¥–µ–Ω—å (MSK)
    return f"{datetime.now(MSK_TZ):%Y-%m-%d}-{salt}"


def _is_allowed_event(title: str) -> bool:
    """–§–∏–ª—å—Ç—Ä—É–µ–º –∞—Ñ–∏—à—É:
       - –æ—Å—Ç–∞–≤–ª—è–µ–º –≤—ã—Å—Ç–∞–≤–∫–∏/–∫–æ–Ω—Ü–µ—Ä—Ç—ã/—Ç–µ–∞—Ç—Ä/—Ñ–µ—Å—Ç–∏–≤–∞–ª–∏ –∏ —Ç.–ø.
       - –∫–∏–Ω–æ/—Ñ–∏–ª—å–º—ã –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —É–ø–æ–º—è–Ω—É—Ç–∞ '–ø—Ä–µ–º—å–µ—Ä–∞'
    """
    t = (title or "").lower()

    allowed_any = [
        "–≤—ã—Å—Ç–∞–≤–∫–∞", "—ç–∫—Å–ø–æ–∑–∏—Ü–∏—è", "–≤–µ—Ä–Ω–∏—Å–∞–∂",
        "–∫–æ–Ω—Ü–µ—Ä—Ç", "—Ñ–µ—Å—Ç–∏–≤–∞–ª—å", "–¥–∂–∞–∑", "—Ä–æ–∫", "–æ—Ä–∫–µ—Å—Ç—Ä", "—Å–∏–º—Ñ–æ–Ω–∏—á–µ—Å–∫–∏–π",
        "—Å–ø–µ–∫—Ç–∞–∫–ª—å", "—Ç–µ–∞—Ç—Ä", "–ø–µ—Ä—Ñ–æ—Ä–º–∞–Ω—Å", "–æ–ø–µ—Ä–∞", "–±–∞–ª–µ—Ç",
        "—è—Ä–º–∞—Ä–∫–∞", "–º–∞—Ä–∫–µ—Ç", "—ç–∫—Å–∫—É—Ä—Å–∏—è",
        "–ª–µ–∫—Ü–∏—è", "–º–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å", "–≤–æ—Ä–∫—à–æ–ø", "–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è",
        "stand-up", "—Å—Ç–µ–Ω–¥–∞–ø", "open mic", "–æ–ø–µ–Ω –º–∞–π–∫"
    ]
    if any(k in t for k in allowed_any):
        return True

    # –∫–∏–Ω–æ/—Ñ–∏–ª—å–º ‚Äî —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å '–ø—Ä–µ–º—å–µ—Ä–∞'
    if ("–∫–∏–Ω–æ" in t or "—Ñ–∏–ª—å–º" in t) and "–ø—Ä–µ–º—å–µ—Ä–∞" in t:
        return True

    return False

# ====== AGRO helpers + —Å–±–æ—Ä—â–∏–∫ ======

def _dedupe_by_url_title(items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    seen: set[tuple[str, str]] = set()
    out: List[Dict[str, Any]] = []
    for it in items:
        u = (it.get("url") or "").strip().lower()
        t = (it.get("title") or "").strip().lower()
        key = (u, t)
        if key in seen:
            continue
        seen.add(key)
        out.append(it)
    return out

def _agro_keep(title: str) -> bool:
    """–§–∏–ª—å—Ç—Ä '–±–∏–∑–Ω–µ—Å‚Äë–ø–æ–≤–µ—Å—Ç–∫–∏' –¥–ª—è –∞–≥—Ä–æ."""
    t = (title or "").lower()

    allow = [
        "—Ä—ã–Ω–æ–∫", "—ç–∫—Å–ø–æ—Ä—Ç", "–∏–º–ø–æ—Ä—Ç", "–∫–≤–æ—Ç–∞", "–≥–æ—Å–ø–æ–¥–¥–µ—Ä–∂", "—Å—É–±—Å–∏–¥",
        "—É—Ä–æ–∂–∞–π", "–ø–æ—Å–µ–≤", "—Å–±–æ—Ä", "–∑–∞—Å—É—Ö–∞", "–ø–æ–≥–æ–¥–∞", "–ø—Ä–æ–≥–Ω–æ–∑", "–≥–∫—Ç",
        "—Ü–µ–Ω–∞", "–ø–æ–¥–æ—Ä–æ–∂–∞–Ω", "–ø–æ–¥–µ—à–µ–≤", "–∏–Ω–¥–µ–∫—Å", "–∏–Ω—Ñ–ª—è—Ü",
        "–∑–µ—Ä–Ω", "–º–∞—Å–ª", "–º–æ–ª–æ–∫", "–º—è—Å", "—Å–∫–æ—Ç", "–ø—Ç–∏—Ü", "—Å–∞—Ö–∞—Ä",
        "–ª–æ–≥–∏—Å—Ç", "–ø–æ—Ä—Ç", "–∂–¥", "–ø–µ—Ä–µ–≤–∞–ª–∫", "—ç–∫—Å–ø–æ—Ä—Ç–Ω–∞—è –ø–æ—à–ª–∏–Ω–∞",
        "—Ç–µ—Ö–Ω–∏–∫–∞", "—Ç–µ—Ö–Ω–æ–ª–æ–≥", "–¥—Ä–æ–Ω", "–∞–≥—Ä–æ—Ç–µ—Ö", "–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏", "–ø—Ä–æ–µ–∫—Ç",
        "–º—Å—Ö", "–º–∏–Ω—Å–µ–ª—å—Ö–æ–∑", "–ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω", "–ø—Ä–∏–∫–∞–∑", "–§–û–¢", "–º–µ—Ä—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏"
    ]
    deny = [
        "—Ä–µ—Ü–µ–ø—Ç", "–∫–∞–∫ –ø–æ—Å–∞–¥–∏—Ç—å", "–æ–≥–æ—Ä–æ–¥", "–¥–∞—á–∞", "—Å–∞–¥–æ–≤–æ–¥",
        "–ª–∞–π—Ñ—Ö–∞–∫", "–º–∞—Ä–∏–Ω–∞–¥", "–∫—É–ª–∏–Ω–∞—Ä", "–ø–æ–¥–∫–æ—Ä–º–∫", "—É–¥–æ–±—Ä–µ–Ω–∏–µ —Å–≤–æ–∏–º–∏",
        "–¥–æ–º–∞—à–Ω", "—Ä–∞—Å—Å–∞–¥–∞", "—Ü–≤–µ—Ç–æ–∫", "–∫–æ–º–Ω–∞—Ç–Ω"
    ]

    if any(x in t for x in deny):
        return False
    return any(x in t for x in allow)

async def get_agro(limit: int = 10) -> List[Dict[str, Any]]:
    """–ù–æ–≤–æ—Å—Ç–∏ –∞–≥—Ä–æ: —Å–∞–π—Ç—ã + Telegram, —Ñ–∏–ª—å—Ç—Ä –±–∏–∑–Ω–µ—Å-–ø–æ–≤–µ—Å—Ç–∫–∏, –¥–µ–¥—É–ø, –¥–Ω–µ–≤–Ω–∞—è —Ä–∞–Ω–¥–æ–º–∏–∑–∞—Ü–∏—è."""
    items: List[Dict[str, Any]] = []

    # --- 1) –ü—Ä–æ—Ñ–∏–ª—å–Ω—ã–µ —Å–∞–π—Ç—ã ---
    sources = [
        "https://www.agroinvestor.ru/news/",
        "https://www.agroxxi.ru/novosti.html",
        "https://mcx.gov.ru/press-service/news/",
    ]
    try:
        async with httpx.AsyncClient(follow_redirects=True, timeout=15) as client:
            for url in sources:
                html_text = await fetch_html(client, url)
                if not html_text:
                    continue
                soup = BeautifulSoup(html_text, "html.parser")
                for a in soup.select("a[href]")[:120]:
                    title = a.get_text(" ", strip=True)
                    href = (a.get("href") or "").strip()
                    if not title or len(title) < 12:
                        continue
                    if not _agro_keep(title):
                        continue
                    # –∞–±—Å–æ–ª—é—Ç–Ω–∞—è —Å—Å—ã–ª–∫–∞
                    if href.startswith("/"):
                        from urllib.parse import urlparse, urljoin
                        base = urlparse(url)
                        href = urljoin(f"{base.scheme}://{base.netloc}", href)
                    if not href.startswith("http"):
                        continue
                    items.append({
                        "title": short(title, 120),
                        "summary": "",
                        "url": href,
                        "image": "",
                        "_src": "site",
                    })
    except Exception:
        pass

    # --- 2) Telegram-–∫–∞–Ω–∞–ª—ã (—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Å–ø–∏—Å–æ–∫ AGRO_TELEGRAM) ---
    try:
        tg = await get_telegram_news(AGRO_TELEGRAM, limit_per_channel=3, total_limit=15)
        for it in tg:
            title = (it.get("title") or "").strip()
            if title and _agro_keep(title):
                items.append({
                    "title": short(title, 120),
                    "summary": short(it.get("summary") or "", 220),
                    "url": it.get("url") or "",
                    "image": it.get("image") or "",
                    "_src": "tg",
                })
    except Exception:
        pass

    # –î–µ–¥—É–ø + –¥–Ω–µ–≤–Ω–∞—è —Ä–∞–Ω–¥–æ–º–∏–∑–∞—Ü–∏—è + –ª–∏–º–∏—Ç
    items = _dedupe_by_url_title(items)
    random.Random(_daily_seed("agro")).shuffle(items)
    return items[:limit]

# ================== SVO (—Ç–µ–ª–µ–≥—Ä–∞–º + —Ñ–∏–ª—å—Ç—Ä + –¥–µ–¥—É–ø) ===================
def _svo_keep(text: str) -> bool:
    """–§–∏–ª—å—Ç—Ä –°–í–û: –º—è–≥—á–µ. –ü—É—Å–∫–∞–µ–º –ü—É—Ç–∏–Ω/–ø–µ—Ä–µ–≥–æ–≤–æ—Ä—ã, –∏–Ω–∞—á–µ –Ω—É–∂–Ω–∞ —Å–≤—è–∑–∫–∞ –∏–∑ 2 –≥—Ä—É–ø–ø."""
    t = (text or "").lower()

    # ‚ùå —á—ë—Ä–Ω—ã–π —Å–ø–∏—Å–æ–∫ (–Ω–µ –ø—Ä–æ –≤–æ–π–Ω—É)
    deny = [
        "–±–ª–æ–≥–µ—Ä", "—à–æ—É–º–µ–Ω", "–∞–∫—Ç—ë—Ä", "–∞–∫—Ç—Ä–∏—Å", "–ø–µ–≤–∏—Ü", "–ø–µ–≤–µ—Ü",
        "—à–æ—É", "–∫–æ–Ω—Ü–µ—Ä—Ç", "—Å–µ—Ä–∏–∞–ª", "–∫–∏–Ω–æ", "–ø—Ä–µ–º—å–µ—Ä–∞", "—Ñ–∏–ª—å–º",
        "–∏–≤–µ–Ω—Ç", "—Å–µ–ª–µ–±", "–∑–≤–µ–∑–¥–∞", "—Å–∫–∞–Ω–¥–∞–ª",
        "–±–∏–∑–Ω–µ—Å", "–∫–æ–º–ø–∞–Ω–∏—è", "–∞–∫—Ü–∏–∏", "–∫—Ä–∏–ø—Ç", "–º–∞–≥–∞–∑–∏–Ω", "–º–æ–¥–∞"
    ]
    if any(x in t for x in deny):
        return False

    # ‚úÖ –º–∞—Ä–∫–µ—Ä—ã —Ç–µ–º—ã
    core = [
        "—Å–≤–æ", "—Å–ø–µ—Ü–æ–ø–µ—Ä–∞—Ü", "–ª–±—Å", "—Ñ—Ä–æ–Ω—Ç", "–≤–æ–µ–Ω–Ω", "—Å–≤–æ–¥–∫", "–º–∏–Ω–æ–±–æ—Ä–æ–Ω—ã",
        "–≤—Å—É", "–∑—Å—É", "–±—Ä–∏–≥–∞–¥–∞", "–±–∞—Ç–∞–ª—å–æ–Ω", "–ø–æ–ª–∫",
        "–∞—Ä—Ç–∏–ª–ª", "–º–∏–Ω–æ–º", "–ø–≤–æ", "–±–ø–ª–∞", "–¥—Ä–æ–Ω", "—à–∞—Ö–µ–¥", "–≥–µ—Ä–∞–Ω—å",
        "—Ä–∞–∫–µ—Ç", "—Ç–∞–Ω–∫", "–±—Ä–æ–Ω–µ—Ç–µ—Ö", "–±–æ–µ–ø—Ä–∏–ø–∞—Å", "–æ–∫–æ–ø", "–∏–Ω–∂–µ–Ω–µ—Ä–Ω",
        "—Å—à–∞", "–∞–º–µ—Ä–∏–∫–∞", "–∑–µ–ª–µ–Ω—Å–∫–∏–π", "–ø—É—Ç–∏–Ω", "–ø–µ—Ä–µ–≥–æ–≤–æ—Ä"
    ]
    actions = [
        "–æ–±—Å—Ç—Ä–µ–ª", "—É–¥–∞—Ä", "—à—Ç—É—Ä–º", "—Ä–µ–π–¥", "–Ω–∞—Å—Ç—É–ø", "–∫–æ–Ω—Ç—Ä–Ω–∞—Å—Ç—É–ø",
        "–ø—Ä–æ—Ä—ã–≤", "–æ–±–æ—Ä–æ–Ω–∞", "—Å–±–∏—Ç", "–ø–æ–¥—Ä—ã–≤", "–≤–∑–æ—Ä–≤–∞–Ω",
        "—ç–≤–∞–∫—É–∞—Ü", "–ø–µ—Ä–µ–±—Ä–æ—Å", "–∑–∞–¥–µ—Ä–∂–∞–Ω", "–∑–∞—á–∏—Å—Ç–∫", "–≤—ã—Å–∞–¥–∫"
    ]
    places = [
        "–±–∞—Ö–º—É—Ç", "–∞—Ä—Ç—ë–º–æ–≤—Å–∫", "–∞–≤–¥–µ–µ–≤", "–∫—É–ø—è–Ω—Å–∫", "–ª–∏–º–∞–Ω", "—Å–≤–∞—Ç–æ–≤–æ",
        "—É–≥–ª–µ–¥–∞—Ä", "–∑–∞–ø–æ—Ä–æ–∂", "—Ö–µ—Ä—Å–æ–Ω", "–¥–æ–Ω–µ—Ü–∫", "–ª—É–≥–∞–Ω—Å–∫",
        "–∫—Ä–µ–º–µ–Ω–Ω", "—á–∞—Å–æ–≤ —è—Ä", "–º–∞—Ä—å–∏–Ω–∫", "—Ä–∞–±–æ—Ç–∏–Ω", "—Ö–∞—Ä–∫–æ–≤", "—Ö–∞—Ä—å–∫–æ–≤"
    ]

    # –Ø–≤–Ω—ã–µ –ø—Ä–æ–ø—É—Å–∫–∏
    if "–ø—É—Ç–∏–Ω" in t or "–ø–µ—Ä–µ–≥–æ–≤–æ—Ä" in t:
        return True

    has_core = any(k in t for k in core)
    has_actions = any(k in t for k in actions)
    has_places = any(k in t for k in places)

    # –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ 2 –∏–∑ 3 –≥—Ä—É–ø–ø, –ª–∏–±–æ core + (actions|places)
    score = sum([has_core, has_actions, has_places])
    return score >= 2 and (has_core or has_actions)


async def get_svo(limit: int = 10) -> List[Dict[str, Any]]:
    """–ù–æ–≤–æ—Å—Ç–∏ –°–í–û –∏–∑ —Ç–µ–ª–µ–≥—Ä–∞–º-–∫–∞–Ω–∞–ª–æ–≤ + –∂—ë—Å—Ç–∫–∏–π —Ñ–∏–ª—å—Ç—Ä –∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è."""
    raw = await get_telegram_news(
        SVO_TELEGRAM,
        limit_per_channel=6,   # –±–µ—Ä—ë–º –ø–æ–±–æ–ª—å—à–µ —Å—ã—Ä—å—è
        total_limit=40
    )

    out: List[Dict[str, Any]] = []
    seen: set[str] = set()

    for it in raw:  # —É–∂–µ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –≤–Ω—É—Ç—Ä–∏ get_telegram_news
        title = (it.get("title") or "").strip()
        if not title or not _svo_keep(title):
            continue

        key = title.lower()
        if key in seen:
            continue
        seen.add(key)

        out.append({
            "title": short(title, 160),
            "summary": short(it.get("summary") or "", 240),
            "url": it.get("url") or "",
            "image": it.get("image") or "",
        })

        if len(out) >= limit:
            break

    return out

# ================== AI (–Ω–æ–≤–æ—Å—Ç–∏, —Å—Ç—Ä–æ–≥–∏–π —Ñ–∏–ª—å—Ç—Ä + –¥–µ–¥—É–ø) ===================
async def get_ai_news(limit: int = 10) -> List[Dict[str, Any]]:
    """AI-–ª–µ–Ω—Ç–∞: –±–µ—Ä—ë–º –∑–∞–≥–æ–ª–æ–≤–∫–∏, —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º, –¥–µ–¥—É–ø–∏–º –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å—Å—ã–ª–∫–∏."""
    sites = [
        "https://techcrunch.com/tag/artificial-intelligence/",
        "https://venturebeat.com/category/ai/",
        "https://www.technologyreview.com/topic/artificial-intelligence/",
        "https://www.theverge.com/artificial-intelligence",
        "https://openai.com/blog/",
        "https://vc.ru/ai",
        "https://rb.ru/tag/iskusstvennyy-intellekt/",
        "https://www.computerra.ru/tag/iskusstvennyj-intellekt/",
    ]

    # —É–∂–µ—Å—Ç–æ—á—ë–Ω–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ (—è–¥—Ä–æ)
    kw_core = [
        "ai", "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç", "–Ω–µ–π—Ä–æ—Å–µ—Ç", "llm", "gpt", "genai",
        "–º–æ–¥–µ–ª—å", "foundation model", "—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä", "r1", "mistral", "llama",
        "distillation", "fine-tuning", "inference", "rag", "agent"
    ]
    # ¬´—Å–∏–≥–Ω–∞–ª—å–Ω—ã–µ¬ª –º–∞—Ä–∫–µ—Ä—ã (—Ä–µ–ª–∏–∑—ã/–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è/–≤–µ—Å–∞/opensource –∏ —Ç.–ø.)
    kw_signal = [
        "—Ä–µ–ª–∏–∑", "–∑–∞–ø—É—Å–∫", "announc", "update", "–æ–±–Ω–æ–≤–ª–µ–Ω", "weights",
        "research", "study", "paper", "benchmark", "sota",
        "open source", "opensource", "github", "—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä", "–¥–∞—Ç–∞—Å–µ—Ç"
    ]

    out: List[Dict[str, Any]] = []
    seen_titles: set[str] = set()
    seen_urls: set[str] = set()

    def good(title: str) -> bool:
        t = (title or "").lower()
        if not any(k in t for k in kw_core):
            return False
        # —É—Å–∏–ª–∏–≤–∞–µ–º –º–∞—Ç–µ—Ä–∏–∞–ª—ã —Å —Å–∏–≥–Ω–∞–ª–∞–º–∏
        if any(k in t for k in kw_signal):
            return True
        # –∏ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —è–≤–Ω–æ ¬´–ø—Ä–æ –º–æ–¥–µ–ª–∏¬ª
        return any(k in t for k in ["model", "–º–æ–¥–µ–ª—å", "llm", "gpt", "mistral", "llama", "r1"])

    async with httpx.AsyncClient(follow_redirects=True, timeout=15) as client:
        for url in sites:
            page = await fetch_html(client, url)
            if not page:
                continue
            soup = BeautifulSoup(page, "html.parser")
            for a in soup.select("a[href]")[:120]:
                title = a.get_text(" ", strip=True)
                href = (a.get("href") or "").strip()
                if not title or len(title) < 20:
                    continue
                if not good(title):
                    continue

                # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö —Å—Å—ã–ª–æ–∫
                if href.startswith("/"):
                    from urllib.parse import urlparse, urljoin
                    base = urlparse(url)
                    href = urljoin(f"{base.scheme}://{base.netloc}", href)
                if not href.startswith("http"):
                    continue

                # –¥–µ–¥—É–ø –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É/—Å—Å—ã–ª–∫–µ
                key_t = title.lower()
                key_u = href.split("?")[0].rstrip("/")
                if key_t in seen_titles or key_u in seen_urls:
                    continue
                seen_titles.add(key_t)
                seen_urls.add(key_u)

                out.append({
                    "title": short(title, 120),
                    "summary": "",
                    "url": href,
                    "image": "",
                })

    random.Random(_daily_seed("ai")).shuffle(out)
    return out[:limit]

# ================== –ê–§–ò–®–ê (KudaGo + –ê—Ñ–∏—à–∞.—Ä—É + Telegram, —Ñ–∏–ª—å—Ç—Ä—ã) ===================
async def get_afisha(limit: int = 10) -> List[Dict[str, Any]]:
    items: List[Dict[str, Any]] = []

    # --- 1) KudaGo ---
    try:
        today = now_ts()
        month = int((datetime.now(MSK_TZ) + timedelta(days=30)).timestamp())
        async with httpx.AsyncClient(follow_redirects=True, timeout=15) as client:
            data = await fetch_json(
                client,
                "https://kudago.com/public-api/v1.4/events/",
                fields="title,dates,place,site_url,images,description",
                location="msk",
                actual_since=today,
                actual_until=month,
                page_size=40,
                order_by="-publication_date",
                expand="place",
                text_format="plain",
            )
            for e in (data or {}).get("results", []):
                title = (e.get("title") or "").strip()
                if not _is_allowed_event(title):
                    continue

                date_str = ""
                dates = e.get("dates") or []
                if dates and dates[0].get("start"):
                    try:
                        start = datetime.fromtimestamp(dates[0]["start"], MSK_TZ)
                        date_str = start.strftime("%d.%m %H:%M")
                    except Exception:
                        pass

                place = (e.get("place") or {}).get("title") or ""
                summary_parts = [date_str, place]
                summary = " ¬∑ ".join(x for x in summary_parts if x) or (e.get("description") or "–°–æ–±—ã—Ç–∏–µ")

                img = e["images"][0].get("image") if e.get("images") else ""
                items.append({
                    "title": short(title, 120),
                    "summary": short(summary, 240),
                    "url": e.get("site_url") or "",
                    "image": img,
                    "_src": "kudago",
                })
    except Exception:
        pass

    # --- 2) Afisha.ru ---
    try:
        async with httpx.AsyncClient(follow_redirects=True, timeout=15) as client:
            html_text = await fetch_html(client, "https://www.afisha.ru/msk/")
            if html_text:
                soup = BeautifulSoup(html_text, "html.parser")
                for a in soup.select("a[href]")[:120]:
                    text = a.get_text(" ", strip=True)
                    href = a.get("href") or ""
                    if not text or len(text) < 8:
                        continue
                    if href.startswith("/"):
                        href = "https://www.afisha.ru" + href
                    if not _is_allowed_event(text):
                        continue
                    items.append({
                        "title": short(text, 120),
                        "summary": "",
                        "url": href,
                        "image": "",
                        "_src": "afisha",
                    })
    except Exception:
        pass

    # --- 3) Telegram ---
    try:
        tg = await get_telegram_news(AFISHA_TELEGRAM, limit_per_channel=3, total_limit=12)
        for it in tg:
            title = (it.get("title") or "").strip()
            if not title:
                continue
            if not _is_allowed_event(title):
                continue
            items.append({
                "title": short(title, 120),
                "summary": short(it.get("summary") or "", 240),
                "url": it.get("url") or "",
                "image": it.get("image") or "",
                "_src": "tg",
            })
    except Exception:
        pass

    # --- —Ä–∞–Ω–¥–æ–º–∏–∑–∞—Ü–∏—è –Ω–∞ –¥–µ–Ω—å –∏ –ª–∏–º–∏—Ç ---
    random.Random(_daily_seed("afisha")).shuffle(items)
    return items[:limit]

def six_months_ago_str() -> str:
    return (datetime.now(MSK_TZ) - timedelta(days=182)).strftime("%Y-%m-%d")

def seed_for_today() -> int:
    """–û–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ seed –Ω–∞ —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É –≤ MSK ‚Äî –ø–æ—Ä—è–¥–æ–∫ –º–µ–Ω—è–µ—Ç—Å—è —Ä–∞–∑ –≤ –¥–µ–Ω—å."""
    return int(datetime.now(MSK_TZ).strftime("%Y%m%d"))

def shuffle_daily(items: list) -> list:
    """–î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ –¥–µ–Ω—å –ø–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–ø–∏—Å–∫–∞."""
    import random
    rnd = random.Random(seed_for_today())
    rnd.shuffle(items)
    return items

async def tmdb_collect(client: httpx.AsyncClient, url: str, base_params: dict, pages: int = 3) -> list[dict]:
    """–°–æ–±–∏—Ä–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–∞–Ω–∏—Ü TMDB –¥–ª—è –±–æ–ª–µ–µ —à–∏—Ä–æ–∫–æ–≥–æ –ø—É–ª–∞, —á–µ–º –æ–¥–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞."""
    out: list[dict] = []
    for p in range(1, pages + 1):
        params = dict(base_params)
        params["page"] = p
        data = await fetch_json(client, url, **params)
        results = (data or {}).get("results", []) or []
        if not results:
            break
        out.extend(results)
    return out

# ================== –û–ë–ù–û–í–õ–ï–ù–û: –°–ï–†–ò–ê–õ–´ (—Ä–∞–Ω–¥–æ–º–∏–∑–∞—Ü–∏—è —Å –¥–Ω–µ–≤–Ω–æ–π —Å–æ–ª—å—é) ==================
async def get_series(limit: int = 5) -> List[Dict[str, Any]]:
    if not TMDB_API_KEY:
        return [{
            "title": "–ù–µ—Ç TMDB –∫–ª—é—á–∞",
            "summary": "–î–æ–±–∞–≤—å—Ç–µ TMDB_API_KEY –≤ .env –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ.",
            "url": "",
            "image": ""
        }]

    url = "https://api.themoviedb.org/3/discover/tv"
    params = {
        "api_key": TMDB_API_KEY,
        "language": "ru-RU",
        "sort_by": "vote_average.desc",
        "vote_average.gte": 7.0,
        "first_air_date.gte": six_months_ago_str(),
        "vote_count.gte": 100,
        "include_adult": "false",
        "page": 1,
    }

    out: List[Dict[str, Any]] = []
    async with httpx.AsyncClient(follow_redirects=True) as client:
        data = await fetch_json(client, url, **params)
        for tv in (data or {}).get("results", []):
            if tv.get("original_language") not in ("en", "ru", "ko", "ja", "es", "fr", "de", "it"):
                continue
            title = tv.get("name") or tv.get("original_name") or "–°–µ—Ä–∏–∞–ª"
            vote = tv.get("vote_average") or 0.0
            cnt = tv.get("vote_count") or 0
            overview = tv.get("overview") or "–û–ø–∏—Å–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç."
            poster = tv.get("poster_path") or ""
            img = f"https://image.tmdb.org/t/p/w780{poster}" if poster else ""
            tmdb_id = tv.get("id")
            more = f"https://www.themoviedb.org/tv/{tmdb_id}" if tmdb_id else ""
            rating_str = f"–†–µ–π—Ç–∏–Ω–≥ TMDB: {vote:.1f} ({cnt} –æ—Ü–µ–Ω–æ–∫)" if vote > 0 else "–†–µ–π—Ç–∏–Ω–≥ TMDB: –Ω/–¥"
            out.append({
                "title": title,
                "summary": f"{rating_str}. {short(overview, 220)}",
                "url": more,
                "image": img,
            })

    # === —Ä–∞–Ω–¥–æ–º–∏–∑–∞—Ü–∏—è –Ω–∞ –¥–µ–Ω—å ===
    today_salt = datetime.now(MSK_TZ).strftime("%Y-%m-%d") + "series"
    random.Random(today_salt).shuffle(out)

    return out[:limit]


# ================== –û–ë–ù–û–í–õ–ï–ù–û: –§–ò–õ–¨–ú–´ (—Ä–∞–Ω–¥–æ–º–∏–∑–∞—Ü–∏—è —Å –¥–Ω–µ–≤–Ω–æ–π —Å–æ–ª—å—é) ===================
async def get_movies(limit: int = 5) -> List[Dict[str, Any]]:
    if not TMDB_API_KEY:
        return [{
            "title": "–ù–µ—Ç TMDB –∫–ª—é—á–∞",
            "summary": "–î–æ–±–∞–≤—å—Ç–µ TMDB_API_KEY –≤ .env –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ.",
            "url": "",
            "image": ""
        }]

    url = "https://api.themoviedb.org/3/discover/movie"
    params = {
        "api_key": TMDB_API_KEY,
        "language": "ru-RU",
        "sort_by": "vote_average.desc",
        "vote_average.gte": 7.0,
        "primary_release_date.gte": six_months_ago_str(),
        "vote_count.gte": 200,
        "include_adult": "false",
        "page": 1,
    }

    out: List[Dict[str, Any]] = []
    async with httpx.AsyncClient(follow_redirects=True) as client:
        data = await fetch_json(client, url, **params)
        for mv in (data or {}).get("results", []):
            if mv.get("original_language") not in ("en", "ru", "ko", "ja", "es", "fr", "de", "it"):
                continue
            title = mv.get("title") or mv.get("original_title") or "–§–∏–ª—å–º"
            vote = mv.get("vote_average") or 0.0
            cnt = mv.get("vote_count") or 0
            overview = mv.get("overview") or "–û–ø–∏—Å–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç."
            poster = mv.get("poster_path") or ""
            img = f"https://image.tmdb.org/t/p/w780{poster}" if poster else ""
            tmdb_id = mv.get("id")
            more = f"https://www.themoviedb.org/movie/{tmdb_id}" if tmdb_id else ""
            rating_str = f"–†–µ–π—Ç–∏–Ω–≥ TMDB: {vote:.1f} ({cnt} –æ—Ü–µ–Ω–æ–∫)" if vote > 0 else "–†–µ–π—Ç–∏–Ω–≥ TMDB: –Ω/–¥"
            out.append({
                "title": title,
                "summary": f"{rating_str}. {short(overview, 220)}",
                "url": more,
                "image": img,
            })

    # === —Ä–∞–Ω–¥–æ–º–∏–∑–∞—Ü–∏—è –Ω–∞ –¥–µ–Ω—å ===
    today_salt = datetime.now(MSK_TZ).strftime("%Y-%m-%d") + "movies"
    random.Random(today_salt).shuffle(out)

    return out[:limit]

# ----------------------- HTML (UI) -----------------------
INDEX_HTML = f"""
<!doctype html>
<html lang="ru">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>{html.escape(APP_TITLE)}</title>

  <!-- PWA / –±–∞–∑–æ–≤—ã–µ –º–µ—Ç–∞ -->
  <meta name="theme-color" content="#0f1115">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="apple-mobile-web-app-title" content="–ú–æ—è –ø–æ–¥–±–æ—Ä–∫–∞">
  <link rel="manifest" href="/static/manifest.webmanifest">

  <!-- –ò–∫–æ–Ω–∫–∏ -->
  <link rel="apple-touch-icon" sizes="180x180" href="/static/icons/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="192x192" href="/static/icons/android-chrome-192x192.png">
  <link rel="icon" type="image/png" sizes="512x512" href="/static/icons/android-chrome-512x512.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/static/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/static/icons/favicon-16x16.png">

  <style>
    :root {{
      --bg:#0f1115; --fg:#e9eef5; --muted:#97a1b3; --card:#171a21; --brand:#4ea3ff;
      --radius:18px;
    }}
    * {{ box-sizing: border-box; }}
    body {{
      margin:0; background:var(--bg); color:var(--fg);
      font:16px/1.5 -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Inter,Arial;
      padding:24px 16px 40px;
    }}
    h1{{ margin:0 0 18px; font-size:36px; font-weight:800; }}

    .grid {{ display:grid; gap:16px; grid-template-columns:repeat(auto-fill,minmax(280px,1fr)); }}
    .card {{
      background:var(--card); border-radius:var(--radius); overflow:hidden; cursor:pointer;
      border:1px solid #202533; transition:.2s transform;
    }}
    .card:hover{{ transform:translateY(-2px); }}
    .thumb{{ width:100%; height:150px; object-fit:cover; display:block; }}
    .title{{ padding:14px 16px 18px; font-size:22px; font-weight:800; }}
    #panel{{ margin-top:22px; }}
    .hidden{{ display:none; }}

    .item{{ background:var(--card); border:1px solid #202533; border-radius:var(--radius); overflow:hidden; margin:14px 0; }}
    .item .cover{{ width:100%; height:220px; object-fit:cover; display:block; }}
    .item .body{{ padding:14px 16px 16px; }}
    .item .name{{ font-size:22px; font-weight:800; margin:0 0 8px; }}
    .item .desc{{ color:var(--muted); margin:0 0 12px; }}
    .btn{{ display:inline-flex; align-items:center; gap:8px; background:#1f2937; color:#fff; text-decoration:none;
      border:1px solid #2a3446; padding:10px 14px; border-radius:11px; font-weight:600; }}

    /* === –ö–Ω–æ–ø–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ PWA + –ø–æ–¥—Å–∫–∞–∑–∫–∞ === */
    .install-btn {{
      position: fixed; right: 16px; top: 16px; z-index: 1000;
      background:#1f2937; color:#fff; border:1px solid #2a3446;
      padding:10px 14px; border-radius:11px; font-weight:600;
      display:none; cursor:pointer;
    }}
    .install-hint {{
      position: fixed; right: 16px; top: 60px; z-index: 1000;
      background:#111827; color:#e5e7eb; border:1px solid #374151;
      padding:10px 12px; border-radius:10px; font-size:14px; display:none;
    }}
  </style>
</head>
<body>
  <h1>{datetime.now(MSK_TZ).strftime("%d %B %Y")}</h1>

  <!-- –ö–Ω–æ–ø–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –∏ –ø–æ–¥—Å–∫–∞–∑–∫–∞ -->
  <button id="installBtn" class="install-btn">üì≤ –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å</button>
  <div id="installHint" class="install-hint">–ù–∞–∂–º–∏—Ç–µ ¬´–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å¬ª, —á—Ç–æ–±—ã –¥–æ–±–∞–≤–∏—Ç—å –Ω–∞ —ç–∫—Ä–∞–Ω</div>

  <div class="grid">
    <div class="card" onclick="openTopic('afisha')">
      <img class="thumb" src="{TOPIC_IMAGES['afisha']}" alt="">
      <div class="title">–ê—Ñ–∏—à–∞ –ú–æ—Å–∫–≤—ã</div>
    </div>
    <div class="card" onclick="openTopic('series')">
      <img class="thumb" src="{TOPIC_IMAGES['series']}" alt="">
      <div class="title">–°–µ—Ä–∏–∞–ª—ã (–∑–∞ 6 –º–µ—Å, ‚â•7.5)</div>
    </div>
    <div class="card" onclick="openTopic('movies')">
      <img class="thumb" src="{TOPIC_IMAGES['movies']}" alt="">
      <div class="title">–§–∏–ª—å–º—ã (–∑–∞ 6 –º–µ—Å, ‚â•7.5)</div>
    </div>
    <div class="card" onclick="openTopic('agro')">
      <img class="thumb" src="{TOPIC_IMAGES['agro']}" alt="">
      <div class="title">–ê–≥—Ä–æ-–±–∏–∑–Ω–µ—Å</div>
    </div>
    <div class="card" onclick="openTopic('svo')">
      <img class="thumb" src="{TOPIC_IMAGES['svo']}" alt="">
      <div class="title">–ù–æ–≤–æ—Å—Ç–∏ –°–í–û</div>
    </div>
    <div class="card" onclick="openTopic('ai')">
      <img class="thumb" src="{TOPIC_IMAGES['ai']}" alt="">
      <div class="title">–ù–æ–≤–æ—Å—Ç–∏ –ò–ò</div>
    </div>
  </div>

  <div id="panel" class="hidden">
    <div id="output"></div>
  </div>

  <!-- –õ–æ–≥–∏–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–∞—Ä—Ç–æ—á–µ–∫ -->
  <script>
    async function openTopic(key) {{
      const panel = document.getElementById('panel');
      const output = document.getElementById('output');
      panel.classList.remove('hidden');
      output.innerHTML = '<div class="item"><div class="body"><div class="name">–ó–∞–≥—Ä—É–∑–∫–∞‚Ä¶</div><p class="desc">–ü–æ–ª—É—á–∞—é –¥–∞–Ω–Ω—ã–µ –¥–ª—è: '+key+'</p></div></div>';

      try {{
        const r = await fetch('/data?topic=' + encodeURIComponent(key), {{
          headers: {{'ngrok-skip-browser-warning': 'true'}}
        }});
        const js = await r.json();
        if (!Array.isArray(js) || js.length === 0) {{
          output.innerHTML = '<div class="item"><div class="body"><div class="name">–ü—É—Å—Ç–æ</div><p class="desc">–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.</p></div></div>';
          return;
        }}
        let html = '';
        js.forEach(function(it) {{
          html += '<div class="item">';
          if (it.image) html += '<img class="cover" src="'+it.image+'" alt="">';
          html += '<div class="body">';
          html += '<div class="name">'+(it.title || '')+'</div>';
          html += '<p class="desc">'+(it.summary || '')+'</p>';
          if (it.url) html += '<a class="btn" target="_blank" rel="noopener" href="'+it.url+'">–ü–æ–¥—Ä–æ–±–Ω–µ–µ ‚Üí</a>';
          html += '</div></div>';
        }});
        output.innerHTML = html;
      }} catch (e) {{
        output.innerHTML = '<div class="item"><div class="body"><div class="name">–û—à–∏–±–∫–∞</div><p class="desc">–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å.</p></div></div>';
      }}
      window.scrollTo({{top: panel.offsetTop - 8, behavior: 'smooth'}});
    }}
  </script>

  <!-- PWA: –∫–Ω–æ–ø–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ + SW -->
  <script>
    let deferredPrompt = null;
    const installBtn = document.getElementById('installBtn');
    const installHint = document.getElementById('installHint');

    // –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–Ω–æ–ø–∫—É, –∫–æ–≥–¥–∞ –±—Ä–∞—É–∑–µ—Ä –¥–∞—ë—Ç –ø—Ä–∞–≤–æ —É—Å—Ç–∞–Ω–æ–≤–∫–∏
    window.addEventListener('beforeinstallprompt', (e) => {{
      e.preventDefault();
      deferredPrompt = e;
      installBtn.style.display = 'block';
      installHint.style.display = 'block';
    }});

    // –ù–∞–∂–∞—Ç–∏–µ –Ω–∞ "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å"
    installBtn.addEventListener('click', async () => {{
      if (!deferredPrompt) return;
      deferredPrompt.prompt();
      const {{ outcome }} = await deferredPrompt.userChoice;
      // –ü—Ä—è—á–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –ø–æ—Å–ª–µ –≤—ã–±–æ—Ä–∞
      installBtn.style.display = 'none';
      installHint.style.display = 'none';
      deferredPrompt = null;
      console.log(outcome === 'accepted' ? '–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ ‚úÖ' : '–û—Ç–º–µ–Ω–µ–Ω–æ ‚ùå');
    }});

    // –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è Service Worker
    if ('serviceWorker' in navigator) {{
      window.addEventListener('load', () => {{
        navigator.serviceWorker.register('/static/sw.js')
          .then(reg => console.log('‚úÖ Service Worker –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω:', reg))
          .catch(err => console.log('‚ùå –û—à–∏–±–∫–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ Service Worker:', err));
      }});
    }}
  </script>
</body>
</html>
"""

# ----------------------- ROUTES -----------------------
@app.get("/", response_class=HTMLResponse)
async def index() -> HTMLResponse:
    return HTMLResponse(INDEX_HTML)

# ===== –û–ë–ù–û–í–õ–ï–ù–û: –¥–æ–±–∞–≤–ª–µ–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä force=1 –¥–ª—è –æ–±—Ö–æ–¥–∞ –∫—ç—à–∞ =====
@app.get("/data", response_class=JSONResponse)
async def data(topic: str = Query(...), force: int = Query(0)) -> JSONResponse:
    topic = (topic or "").lower().strip()

    if not force:
        cached = cache_get(topic)
        if cached is not None:
            return JSONResponse(cached)

    items: List[Dict[str, Any]] = []
    try:
        if topic == "afisha":
            items = await get_afisha(limit=10)
        elif topic == "series":
            items = await get_series(limit=5)
        elif topic == "movies":
            items = await get_movies(limit=5)
        elif topic == "agro":
            items = await get_agro(limit=10)
        elif topic == "svo":
            items = await get_svo(limit=10)
        elif topic == "ai":
            items = await get_ai_news(limit=10)
        else:
            items = []
    except Exception:
        items = []

    cache_set(topic, items)
    return JSONResponse(items)